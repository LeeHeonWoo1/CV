## Multi Modal AI
<span style="background-color: #FFFB00;">멀티 모달이란, 여러 개의 모달리티</span>라는 뜻으로, 모달리티의 경우 직영하면 **양식 혹은 양상**을 뜻한다.

데이터의 관점에서 보면 모달리티라는 것은, 데이터의 형식을 의미하며 멀티 모달AI는 결국 여러개의 데이터 형식을 가지고 학습되어지는 모델을 의미한다.

## 가장 큰 차이점

여지껏 지도학습을 기준으로 기존 모델이 작동하는 방식을 확인해 보면, **한 개의 데이터 형식을 input**으로 넣어서 학습시켰다. 하지만 **멀티 모달은 두 개 이상의 데이터를 input으로 넣을 수 있다**.

예를 들면, 이미지 + 텍스트를 input으로 넣거나 이미지 + 정형 데이터를 input으로 넣을 수 있다. 예전에는 영상데이터가 있으면 영상 데이터를 한 프레임씩 잘라서 이미지로 변환한 다음 해당 이미지에 대한 내용만 가지고 모델 학습을 시켰다면, 멀티모달에서는 추출한 이미지에 맞는 오디오 데이터를 함께 학습시켜 영상에서 제공하는 모든 데이터를 사용하여 학습할 수 있다.

## 멀티모달 vs 멀티모델

멀티모달이라는 단어 자체가 익숙하지 않다 보니, "멀티 모델"이라고 부르는 사람들도 있는데, 이는 동일하지 않다. 물론 멀티모달 또한 여러 유형의 데이터를 사용하다 보니 여러 개의 모델을 사용하긴 하지만, 차이는 데이터 유형의 개수에 따라 다르다. 

- **멀티모델**의 경우 **앙상블 학습**에 더 가까우며, 1가지 종류의 데이터에 대해 모델의 성능을 끌어올리기 위해서 여러 개의 모델을 결합하는 학습 방식을 의미한다.
- **멀티모달**의 경우 2가지 이상의 서로 다른 종류의 데이터에 대해서 학습 시키는 형태이며, 모델은 1개가 될 수 있고, 두 개 이상이 될 수 있다.

## 멀티모달의 종류

<div align=center><img src=./image_for_markdown/multi_modal_cls.png></div>

멀티 모달에는 크게 3가지 종류가 있다. **MultiModal Deep Learning**이라는 논문에서는 Early Fusion, Late Fusion, Joint or Intermediate Fusion으로 그 종류를 나눈다.

- Early Fusion
    + Early Fusion은 **종류가 다른 두 가지 데이터를 하나의 데이터로 먼저 합친 이후 학습을 진행**하는 경우를 의미한다.
    + 이 때 형식이 다른 두 데이터를 합치기 위해서는 다양한 방식의 데이터 변환이 이루어진다.
- Late Fusion
    + Late Fusion은 **종류가 다른 두 가지 데이터를 각각 다른 모델에 학습시킨 이후 나온 결과를 융합**하는 경우를 의미한다.
    + 기존의 앙상블 모델 학습 방식과 비슷하다.
- Joint or Intermediate Fusion
    + Joint Fusion은 **두 개의 모달리티 데이터를 동시에 학습시키지 않고 내가 원하는 모델의 깊이에서 모달리티를 병합할 수 있는 유연성**을 가지고 있다.
    + 하나의 모달리티로 모델 학습을 진행하다가 모델 학습의 마지막 레이어 전에 다른 모달리티와 융합하는 방법으로, 이 과정을 **end-to-end learning**이라고도 한다.

    <div align=center><img src=./image_for_markdown/joint_fusion.png></div> 

    + 위 그림에서 볼 수 있듯, 서로다른 모달을 가진 세 개의 데이터(이미지, 좌표값, 거리)가 모델의 Layer층으로 들어가서 feature extraction을 수행하고 그 중 데이터의 특징을 가진 feature만 추출하여 세 개 데이터의 특징을 하나의 데이터로 융합한다. 마지막 분류모델을 거쳐서 결과를 출력한다.

## Usage
사용되는 방식으로는 아래와 같은 방식들이 있다.

- 이미지 캡셔닝(Image Captioning)
    + 모델은 이미지의 시각적 특징을 이해하고, 그에 맞는 자연어로 캡션을 생성한다.
    + 예를 들어, 고양이가 있는 이미지에 대해 설명을 생성할 수 있다.
- 시각적 질문 응답(Visual Question Answering)
    + 이미지와 관련된 질문에 대한 답을 자연어로 생성한다.
    + 이미지에 대한 질의에 맞는 답을 이해한 후에 생성할 수 있다.
- 이미지 분류 및 검색(Image Classification and Retrieval)
    + 이미지에 대한 텍스트 설명이나 태그를 활용하여 이미지를 분류하거나, 특정 텍스트 쿼리에 대한 이미지를 검색한다.
- 감정 분석(Emotion Analysis)
    + 이미지와 관련된 얼굴 표정 및 텍스트 데이터를 결합하여 보다 정확한 감정 분석을 수행할 수 있다.

이러한 작업을 수행하기 위해서는 텍스트와 이미지 데이터를 통합적으로 이해하고 처리할 수 있는 모델이 필요하다. 예시는 아래와 같은 모델들이 있다.

### CLIP(Constrastive Language-Image Pre-Training)
CLIP은 OpenAI사에서 개발한 언어-이미지 멀티모달 AI모델로, 대규모 웹 언어-이미지 병렬 데이터셋에서 언어와 이미지 간의 상호작용을 학습하는 방식으로 구성되어 있다.

<div align=center><img src=./image_for_markdown/CLIP.png></div>