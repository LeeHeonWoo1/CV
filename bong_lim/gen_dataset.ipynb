{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Time</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.71</td>\n",
       "      <td>300.96</td>\n",
       "      <td>2023-11-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.23</td>\n",
       "      <td>316.30</td>\n",
       "      <td>2023-11-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.45</td>\n",
       "      <td>310.35</td>\n",
       "      <td>2023-11-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.14</td>\n",
       "      <td>312.53</td>\n",
       "      <td>2023-11-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122.03</td>\n",
       "      <td>317.21</td>\n",
       "      <td>2023-11-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>110.03</td>\n",
       "      <td>314.42</td>\n",
       "      <td>2024-01-31 19:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>120.02</td>\n",
       "      <td>306.80</td>\n",
       "      <td>2024-01-31 20:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>123.36</td>\n",
       "      <td>311.37</td>\n",
       "      <td>2024-01-31 21:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>116.31</td>\n",
       "      <td>301.87</td>\n",
       "      <td>2024-01-31 22:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>114.29</td>\n",
       "      <td>314.07</td>\n",
       "      <td>2024-01-31 23:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2208 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Temp   Speed                 Time  Count\n",
       "0     112.71  300.96  2023-11-01 00:00:00      0\n",
       "1     106.23  316.30  2023-11-01 01:00:00      0\n",
       "2     113.45  310.35  2023-11-01 02:00:00      0\n",
       "3     103.14  312.53  2023-11-01 03:00:00      0\n",
       "4     122.03  317.21  2023-11-01 04:00:00      0\n",
       "...      ...     ...                  ...    ...\n",
       "2203  110.03  314.42  2024-01-31 19:00:00      1\n",
       "2204  120.02  306.80  2024-01-31 20:00:00      1\n",
       "2205  123.36  311.37  2024-01-31 21:00:00      1\n",
       "2206  116.31  301.87  2024-01-31 22:00:00      1\n",
       "2207  114.29  314.07  2024-01-31 23:00:00      1\n",
       "\n",
       "[2208 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 생성을 위한 함수 정의\n",
    "def generate_data(num_rows):\n",
    "    data = []\n",
    "    start_date = datetime(2023, 11, 1)\n",
    "    end_date = datetime(2024, 1, 31)\n",
    "    current_date = start_date\n",
    "\n",
    "    for _ in range(num_rows):\n",
    "        temp = round(random.uniform(100, 130), 2)\n",
    "        speed = round(random.uniform(300, 320), 2)\n",
    "        count = 0\n",
    "        \n",
    "        data.append({\n",
    "            'Temp': temp,\n",
    "            'Speed': speed,\n",
    "            'Time': current_date.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'Count': count\n",
    "        })\n",
    "        \n",
    "        current_date += timedelta(hours=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 생성\n",
    "num_rows = int((datetime(2024, 2, 1) - datetime(2023, 11, 1)).total_seconds() / 3600)  # 총 시간대 수\n",
    "data = generate_data(num_rows)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 드릴이 고장난 시점 설정\n",
    "failure_date = random.randint(0, num_rows)\n",
    "df.loc[failure_date:, 'Count'] = df.loc[failure_date:, 'Count'].apply(lambda x: x + 1)\n",
    "\n",
    "# 데이터프레임 출력\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Status\"] = df[\"Count\"].values\n",
    "df[\"Count\"] = 0\n",
    "a = df[\"Status\"].values.tolist()\n",
    "np.random.shuffle(a)\n",
    "df['Status'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, df.shape[0]):\n",
    "    if df[\"Status\"][i] == 1:\n",
    "        df['Count'][i] = df[\"Count\"][i-1]+1\n",
    "    else:\n",
    "        df[\"Count\"][i] = df[\"Count\"][i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./test.csv\", encoding=\"utf8\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "88/88 [==============================] - 4s 20ms/step - loss: 0.1804 - val_loss: 0.1702\n",
      "Epoch 2/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.1672 - val_loss: 0.1697\n",
      "Epoch 3/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1667 - val_loss: 0.1695\n",
      "Epoch 4/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1664 - val_loss: 0.1696\n",
      "Epoch 5/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1661 - val_loss: 0.1699\n",
      "Epoch 6/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1659 - val_loss: 0.1703\n",
      "Epoch 7/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1657 - val_loss: 0.1707\n",
      "Epoch 8/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1654 - val_loss: 0.1710\n",
      "Epoch 9/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1652 - val_loss: 0.1713\n",
      "Epoch 10/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1650 - val_loss: 0.1716\n",
      "Epoch 11/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1647 - val_loss: 0.1718\n",
      "Epoch 12/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1644 - val_loss: 0.1722\n",
      "Epoch 13/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1641 - val_loss: 0.1725\n",
      "Epoch 14/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1637 - val_loss: 0.1729\n",
      "Epoch 15/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1631 - val_loss: 0.1736\n",
      "Epoch 16/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1623 - val_loss: 0.1753\n",
      "Epoch 17/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1614 - val_loss: 0.1774\n",
      "Epoch 18/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1605 - val_loss: 0.1791\n",
      "Epoch 19/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1598 - val_loss: 0.1793\n",
      "Epoch 20/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1592 - val_loss: 0.1784\n",
      "Epoch 21/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1581 - val_loss: 0.1776\n",
      "Epoch 22/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1567 - val_loss: 0.1786\n",
      "Epoch 23/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1552 - val_loss: 0.1786\n",
      "Epoch 24/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1541 - val_loss: 0.1786\n",
      "Epoch 25/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1541 - val_loss: 0.1762\n",
      "Epoch 26/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1515 - val_loss: 0.1742\n",
      "Epoch 27/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1502 - val_loss: 0.1780\n",
      "Epoch 28/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1483 - val_loss: 0.1736\n",
      "Epoch 29/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1472 - val_loss: 0.1781\n",
      "Epoch 30/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1426 - val_loss: 0.1810\n",
      "Epoch 31/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1391 - val_loss: 0.1798\n",
      "Epoch 32/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1357 - val_loss: 0.1841\n",
      "Epoch 33/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1350 - val_loss: 0.1809\n",
      "Epoch 34/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1301 - val_loss: 0.1867\n",
      "Epoch 35/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1276 - val_loss: 0.1847\n",
      "Epoch 36/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1288 - val_loss: 0.1876\n",
      "Epoch 37/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1248 - val_loss: 0.1902\n",
      "Epoch 38/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1199 - val_loss: 0.2007\n",
      "Epoch 39/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.1164 - val_loss: 0.1986\n",
      "Epoch 40/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.1158 - val_loss: 0.2028\n",
      "Epoch 41/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1125 - val_loss: 0.2006\n",
      "Epoch 42/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1074 - val_loss: 0.2142\n",
      "Epoch 43/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.1058 - val_loss: 0.2156\n",
      "Epoch 44/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1058 - val_loss: 0.2078\n",
      "Epoch 45/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.1002 - val_loss: 0.2137\n",
      "Epoch 46/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0972 - val_loss: 0.2172\n",
      "Epoch 47/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0919 - val_loss: 0.2112\n",
      "Epoch 48/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0864 - val_loss: 0.2248\n",
      "Epoch 49/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0920 - val_loss: 0.2072\n",
      "Epoch 50/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0817 - val_loss: 0.2164\n",
      "Epoch 51/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0812 - val_loss: 0.2298\n",
      "Epoch 52/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0737 - val_loss: 0.2241\n",
      "Epoch 53/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0711 - val_loss: 0.2257\n",
      "Epoch 54/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0717 - val_loss: 0.2219\n",
      "Epoch 55/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0676 - val_loss: 0.2340\n",
      "Epoch 56/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0741 - val_loss: 0.2388\n",
      "Epoch 57/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0696 - val_loss: 0.2386\n",
      "Epoch 58/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0610 - val_loss: 0.2411\n",
      "Epoch 59/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0593 - val_loss: 0.2417\n",
      "Epoch 60/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0559 - val_loss: 0.2437\n",
      "Epoch 61/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0543 - val_loss: 0.2558\n",
      "Epoch 62/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0589 - val_loss: 0.2536\n",
      "Epoch 63/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0511 - val_loss: 0.2569\n",
      "Epoch 64/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0490 - val_loss: 0.2518\n",
      "Epoch 65/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0506 - val_loss: 0.2473\n",
      "Epoch 66/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0445 - val_loss: 0.2464\n",
      "Epoch 67/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0455 - val_loss: 0.2513\n",
      "Epoch 68/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0393 - val_loss: 0.2506\n",
      "Epoch 69/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0378 - val_loss: 0.2520\n",
      "Epoch 70/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0371 - val_loss: 0.2552\n",
      "Epoch 71/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0322 - val_loss: 0.2626\n",
      "Epoch 72/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0257 - val_loss: 0.2664\n",
      "Epoch 73/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0229 - val_loss: 0.2700\n",
      "Epoch 74/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0193 - val_loss: 0.2726\n",
      "Epoch 75/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.2750\n",
      "Epoch 76/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.2707\n",
      "Epoch 77/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0152 - val_loss: 0.2750\n",
      "Epoch 78/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0190 - val_loss: 0.2675\n",
      "Epoch 79/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0262 - val_loss: 0.2765\n",
      "Epoch 80/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0232 - val_loss: 0.2755\n",
      "Epoch 81/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0217 - val_loss: 0.2672\n",
      "Epoch 82/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0250 - val_loss: 0.2575\n",
      "Epoch 83/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0241 - val_loss: 0.2658\n",
      "Epoch 84/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0215 - val_loss: 0.2615\n",
      "Epoch 85/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0198 - val_loss: 0.2641\n",
      "Epoch 86/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 0.2763\n",
      "Epoch 87/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0121 - val_loss: 0.2665\n",
      "Epoch 88/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.2679\n",
      "Epoch 89/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.2734\n",
      "Epoch 90/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.2706\n",
      "Epoch 91/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0072 - val_loss: 0.2712\n",
      "Epoch 92/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.2731\n",
      "Epoch 93/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.2718\n",
      "Epoch 94/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.2723\n",
      "Epoch 95/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.2767\n",
      "Epoch 96/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.2720\n",
      "Epoch 97/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0105 - val_loss: 0.2669\n",
      "Epoch 98/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0235 - val_loss: 0.2761\n",
      "Epoch 99/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0274 - val_loss: 0.2733\n",
      "Epoch 100/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0578 - val_loss: 0.2710\n",
      "Epoch 101/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0348 - val_loss: 0.2836\n",
      "Epoch 102/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0192 - val_loss: 0.2827\n",
      "Epoch 103/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.2920\n",
      "Epoch 104/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0118 - val_loss: 0.2863\n",
      "Epoch 105/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.2856\n",
      "Epoch 106/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.2888\n",
      "Epoch 107/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.2879\n",
      "Epoch 108/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.2879\n",
      "Epoch 109/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.2887\n",
      "Epoch 110/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.2893\n",
      "Epoch 111/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.2895\n",
      "Epoch 112/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.2900\n",
      "Epoch 113/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.2894\n",
      "Epoch 114/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.2916\n",
      "Epoch 115/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.2896\n",
      "Epoch 116/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.2930\n",
      "Epoch 117/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0029 - val_loss: 0.2928\n",
      "Epoch 118/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.2921\n",
      "Epoch 119/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0103 - val_loss: 0.2727\n",
      "Epoch 120/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.2829\n",
      "Epoch 121/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0376 - val_loss: 0.2764\n",
      "Epoch 122/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0521 - val_loss: 0.2877\n",
      "Epoch 123/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0395 - val_loss: 0.2810\n",
      "Epoch 124/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0285 - val_loss: 0.2849\n",
      "Epoch 125/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 0.2844\n",
      "Epoch 126/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.2877\n",
      "Epoch 127/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0062 - val_loss: 0.2888\n",
      "Epoch 128/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.2922\n",
      "Epoch 129/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.2936\n",
      "Epoch 130/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.2946\n",
      "Epoch 131/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.2951\n",
      "Epoch 132/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.2953\n",
      "Epoch 133/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.2953\n",
      "Epoch 134/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.2953\n",
      "Epoch 135/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.2953\n",
      "Epoch 136/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.2952\n",
      "Epoch 137/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.2951\n",
      "Epoch 138/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.2950\n",
      "Epoch 139/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.2950\n",
      "Epoch 140/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.2949\n",
      "Epoch 141/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.2949\n",
      "Epoch 142/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.2949\n",
      "Epoch 143/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.2949\n",
      "Epoch 144/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.2949\n",
      "Epoch 145/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.2949\n",
      "Epoch 146/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.2949\n",
      "Epoch 147/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.2948\n",
      "Epoch 148/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.2947\n",
      "Epoch 149/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.2944\n",
      "Epoch 150/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.2955\n",
      "Epoch 151/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.2934\n",
      "Epoch 152/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.2938\n",
      "Epoch 153/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.2817\n",
      "Epoch 154/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0801 - val_loss: 0.2790\n",
      "Epoch 155/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.1008 - val_loss: 0.2643\n",
      "Epoch 156/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0543 - val_loss: 0.2588\n",
      "Epoch 157/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0460 - val_loss: 0.2493\n",
      "Epoch 158/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0198 - val_loss: 0.2624\n",
      "Epoch 159/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.2682\n",
      "Epoch 160/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.2675\n",
      "Epoch 161/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.2700\n",
      "Epoch 162/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.2707\n",
      "Epoch 163/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.2725\n",
      "Epoch 164/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.2720\n",
      "Epoch 165/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.2720\n",
      "Epoch 166/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.2722\n",
      "Epoch 167/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.2713\n",
      "Epoch 168/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.2716\n",
      "Epoch 169/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.2719\n",
      "Epoch 170/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.2721\n",
      "Epoch 171/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.2723\n",
      "Epoch 172/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.2725\n",
      "Epoch 173/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.2726\n",
      "Epoch 174/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.2729\n",
      "Epoch 175/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.2730\n",
      "Epoch 176/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.2732\n",
      "Epoch 177/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.2734\n",
      "Epoch 178/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.2735\n",
      "Epoch 179/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.2737\n",
      "Epoch 180/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.2739\n",
      "Epoch 181/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.2740\n",
      "Epoch 182/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.2742\n",
      "Epoch 183/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.2743\n",
      "Epoch 184/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.2745\n",
      "Epoch 185/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.2747\n",
      "Epoch 186/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.2748\n",
      "Epoch 187/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.2750\n",
      "Epoch 188/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.2752\n",
      "Epoch 189/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.2753\n",
      "Epoch 190/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.2755\n",
      "Epoch 191/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.2758\n",
      "Epoch 192/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.2760\n",
      "Epoch 193/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.2763\n",
      "Epoch 194/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.2766\n",
      "Epoch 195/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.2769\n",
      "Epoch 196/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.2773\n",
      "Epoch 197/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.2778\n",
      "Epoch 198/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.2783\n",
      "Epoch 199/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.2786\n",
      "Epoch 200/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.2780\n",
      "Epoch 201/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0236 - val_loss: 0.3051\n",
      "Epoch 202/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0976 - val_loss: 0.2640\n",
      "Epoch 203/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0695 - val_loss: 0.2768\n",
      "Epoch 204/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0555 - val_loss: 0.2677\n",
      "Epoch 205/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0377 - val_loss: 0.2652\n",
      "Epoch 206/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0215 - val_loss: 0.2654\n",
      "Epoch 207/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.2793\n",
      "Epoch 208/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0087 - val_loss: 0.2781\n",
      "Epoch 209/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.2809\n",
      "Epoch 210/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.2794\n",
      "Epoch 211/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.2813\n",
      "Epoch 212/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.2806\n",
      "Epoch 213/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.2808\n",
      "Epoch 214/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.2808\n",
      "Epoch 215/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.2810\n",
      "Epoch 216/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.2812\n",
      "Epoch 217/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.2814\n",
      "Epoch 218/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.2817\n",
      "Epoch 219/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.2819\n",
      "Epoch 220/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.2821\n",
      "Epoch 221/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.2823\n",
      "Epoch 222/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.2825\n",
      "Epoch 223/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.2827\n",
      "Epoch 224/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.2827\n",
      "Epoch 225/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 9.8099e-04 - val_loss: 0.2831\n",
      "Epoch 226/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 9.5963e-04 - val_loss: 0.2830\n",
      "Epoch 227/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.2830\n",
      "Epoch 228/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 9.2804e-04 - val_loss: 0.2833\n",
      "Epoch 229/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 8.9853e-04 - val_loss: 0.2830\n",
      "Epoch 230/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 9.2295e-04 - val_loss: 0.2840\n",
      "Epoch 231/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.2856\n",
      "Epoch 232/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 9.0502e-04 - val_loss: 0.2847\n",
      "Epoch 233/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 8.7502e-04 - val_loss: 0.2843\n",
      "Epoch 234/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 8.5312e-04 - val_loss: 0.2840\n",
      "Epoch 235/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 8.3363e-04 - val_loss: 0.2837\n",
      "Epoch 236/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 8.1987e-04 - val_loss: 0.2837\n",
      "Epoch 237/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 8.1124e-04 - val_loss: 0.2838\n",
      "Epoch 238/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 8.0474e-04 - val_loss: 0.2838\n",
      "Epoch 239/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.9930e-04 - val_loss: 0.2839\n",
      "Epoch 240/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.9447e-04 - val_loss: 0.2840\n",
      "Epoch 241/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.9010e-04 - val_loss: 0.2841\n",
      "Epoch 242/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.8611e-04 - val_loss: 0.2842\n",
      "Epoch 243/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.8240e-04 - val_loss: 0.2842\n",
      "Epoch 244/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.7897e-04 - val_loss: 0.2843\n",
      "Epoch 245/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.7575e-04 - val_loss: 0.2844\n",
      "Epoch 246/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.7275e-04 - val_loss: 0.2845\n",
      "Epoch 247/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.6991e-04 - val_loss: 0.2846\n",
      "Epoch 248/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.6725e-04 - val_loss: 0.2846\n",
      "Epoch 249/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.6473e-04 - val_loss: 0.2847\n",
      "Epoch 250/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.6237e-04 - val_loss: 0.2848\n",
      "Epoch 251/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.6013e-04 - val_loss: 0.2848\n",
      "Epoch 252/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.5801e-04 - val_loss: 0.2849\n",
      "Epoch 253/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.5601e-04 - val_loss: 0.2850\n",
      "Epoch 254/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.5409e-04 - val_loss: 0.2850\n",
      "Epoch 255/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.5230e-04 - val_loss: 0.2851\n",
      "Epoch 256/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.5059e-04 - val_loss: 0.2852\n",
      "Epoch 257/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.4895e-04 - val_loss: 0.2853\n",
      "Epoch 258/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.4741e-04 - val_loss: 0.2853\n",
      "Epoch 259/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.4593e-04 - val_loss: 0.2854\n",
      "Epoch 260/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.4454e-04 - val_loss: 0.2855\n",
      "Epoch 261/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.4321e-04 - val_loss: 0.2856\n",
      "Epoch 262/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.4194e-04 - val_loss: 0.2856\n",
      "Epoch 263/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.4073e-04 - val_loss: 0.2857\n",
      "Epoch 264/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.3959e-04 - val_loss: 0.2858\n",
      "Epoch 265/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.3849e-04 - val_loss: 0.2858\n",
      "Epoch 266/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.3745e-04 - val_loss: 0.2859\n",
      "Epoch 267/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.3646e-04 - val_loss: 0.2860\n",
      "Epoch 268/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.3552e-04 - val_loss: 0.2860\n",
      "Epoch 269/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.3461e-04 - val_loss: 0.2861\n",
      "Epoch 270/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.3376e-04 - val_loss: 0.2862\n",
      "Epoch 271/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.3294e-04 - val_loss: 0.2862\n",
      "Epoch 272/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.3215e-04 - val_loss: 0.2863\n",
      "Epoch 273/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.3141e-04 - val_loss: 0.2864\n",
      "Epoch 274/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.3070e-04 - val_loss: 0.2864\n",
      "Epoch 275/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.3002e-04 - val_loss: 0.2865\n",
      "Epoch 276/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2938e-04 - val_loss: 0.2866\n",
      "Epoch 277/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2876e-04 - val_loss: 0.2867\n",
      "Epoch 278/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.2817e-04 - val_loss: 0.2867\n",
      "Epoch 279/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2761e-04 - val_loss: 0.2867\n",
      "Epoch 280/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2708e-04 - val_loss: 0.2869\n",
      "Epoch 281/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2657e-04 - val_loss: 0.2869\n",
      "Epoch 282/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2608e-04 - val_loss: 0.2870\n",
      "Epoch 283/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2562e-04 - val_loss: 0.2871\n",
      "Epoch 284/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.2518e-04 - val_loss: 0.2872\n",
      "Epoch 285/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2475e-04 - val_loss: 0.2872\n",
      "Epoch 286/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2435e-04 - val_loss: 0.2873\n",
      "Epoch 287/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2396e-04 - val_loss: 0.2874\n",
      "Epoch 288/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2359e-04 - val_loss: 0.2875\n",
      "Epoch 289/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2324e-04 - val_loss: 0.2876\n",
      "Epoch 290/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2291e-04 - val_loss: 0.2877\n",
      "Epoch 291/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2259e-04 - val_loss: 0.2878\n",
      "Epoch 292/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2228e-04 - val_loss: 0.2879\n",
      "Epoch 293/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.2199e-04 - val_loss: 0.2879\n",
      "Epoch 294/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2171e-04 - val_loss: 0.2881\n",
      "Epoch 295/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2145e-04 - val_loss: 0.2881\n",
      "Epoch 296/300\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 7.2119e-04 - val_loss: 0.2882\n",
      "Epoch 297/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2095e-04 - val_loss: 0.2883\n",
      "Epoch 298/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2072e-04 - val_loss: 0.2885\n",
      "Epoch 299/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2050e-04 - val_loss: 0.2885\n",
      "Epoch 300/300\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 7.2028e-04 - val_loss: 0.2886\n",
      "Train Loss: 0.0584\n",
      "Test Loss: 0.2855\n"
     ]
    }
   ],
   "source": [
    "X = df[['Temp', 'Speed', 'Count']].values\n",
    "y = df['Status'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ndArray 형태로 변환\n",
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps), :])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "TIME_STEPS = 24  # 1일치 데이터를 기반으로 예측\n",
    "X, y = create_dataset(X_scaled, y, TIME_STEPS)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential(\n",
    "    [\n",
    "        LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation=\"tanh\"),\n",
    "        LSTM(units=32, activation=\"tanh\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=16, validation_split=0.2, shuffle=False)\n",
    "\n",
    "# 모델 평가\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 24, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 10ms/step\n",
      "Real status: 1 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 9ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 8ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 8ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 8ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 8ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 7ms/step\n",
      "Real status: 1 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 1 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 7ms/step\n",
      "Real status: 1 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 0 -- Predicted status: 0\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 1 -- Predicted status: 1\n",
      "14/14 [==============================] - 0s 7ms/step\n",
      "Real status: 0 -- Predicted status: 1\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "Real status: 0 -- Predicted status: 1\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과 출력\n",
    "for i in range(20):\n",
    "    result = model.predict(X_test)[i][0]\n",
    "    if result >= 0.5:\n",
    "        print(f'Real status: {y_test[i]} -- Predicted status: 1')\n",
    "    else:\n",
    "        print(f'Real status: {y_test[i]} -- Predicted status: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.17771819670041236\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SARIMA 모델 학습\n",
    "model = SARIMAX(df['Count'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 24))  # 예시로 (1,1,1)과 (1,1,1,24)를 사용\n",
    "result = model.fit()\n",
    "\n",
    "# 과거 데이터와 예측 결과 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.index, df['Count'], label='Actual')\n",
    "plt.plot(df.index, result.fittedvalues, label='Predicted')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델 성능 평가\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(df['Count'], result.fittedvalues)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'The `start` argument could not be matched to a location related to the index of the data.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:249\u001b[0m, in \u001b[0;36mget_index_label_loc\u001b[1;34m(key, index, row_labels)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[1;32m--> 249\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mrow_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('1970-01-01 01:00:00.000002207')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:358\u001b[0m, in \u001b[0;36mget_prediction_index\u001b[1;34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 358\u001b[0m     start, _, start_oos \u001b[38;5;241m=\u001b[39m \u001b[43mget_index_label_loc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrow_labels\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:281\u001b[0m, in \u001b[0;36mget_index_label_loc\u001b[1;34m(key, index, row_labels)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loc, index, index_was_expanded\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:245\u001b[0m, in \u001b[0;36mget_index_label_loc\u001b[1;34m(key, index, row_labels)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     loc, index, index_was_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mget_index_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:195\u001b[0m, in \u001b[0;36mget_index_loc\u001b[1;34m(key, index)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m    196\u001b[0m loc \u001b[38;5;241m=\u001b[39m key\n",
      "\u001b[1;31mKeyError\u001b[0m: 'only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m new_index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], periods\u001b[38;5;241m=\u001b[39mforecast_periods\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# SARIMA 모델을 사용하여 예측\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m forecast \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\base\\wrapper.py:113\u001b[0m, in \u001b[0;36mmake_wrapper.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how[\u001b[38;5;241m0\u001b[39m], how[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how:\n\u001b[1;32m--> 113\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3487\u001b[0m, in \u001b[0;36mMLEResults.predict\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, **kwargs)\u001b[0m\n\u001b[0;32m   3422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3423\u001b[0m \u001b[38;5;124;03mIn-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[0;32m   3424\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3484\u001b[0m \u001b[38;5;124;03m    including confidence intervals.\u001b[39;00m\n\u001b[0;32m   3485\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3486\u001b[0m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[1;32m-> 3487\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_prediction(\n\u001b[0;32m   3488\u001b[0m     start, end, dynamic, information_set\u001b[38;5;241m=\u001b[39minformation_set,\n\u001b[0;32m   3489\u001b[0m     signal_only\u001b[38;5;241m=\u001b[39msignal_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_results\u001b[38;5;241m.\u001b[39mpredicted_mean\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3340\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   3336\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3338\u001b[0m \u001b[38;5;66;03m# Handle start, end, dynamic\u001b[39;00m\n\u001b[0;32m   3339\u001b[0m start, end, out_of_sample, prediction_index \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 3340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_prediction_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3342\u001b[0m \u001b[38;5;66;03m# Handle `dynamic`\u001b[39;00m\n\u001b[0;32m   3343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dynamic, (\u001b[38;5;28mstr\u001b[39m, dt\u001b[38;5;241m.\u001b[39mdatetime, pd\u001b[38;5;241m.\u001b[39mTimestamp)):\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836\u001b[0m, in \u001b[0;36mTimeSeriesModel._get_prediction_index\u001b[1;34m(self, start, end, index, silent)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;124;03mGet the location of a specific key in an index or model row labels\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;124;03msince we have required them to be full indexes, there is no ambiguity).\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    835\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog)\n\u001b[1;32m--> 836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_prediction_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_generated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_generated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\CudaTest\\test_cuda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:362\u001b[0m, in \u001b[0;36mget_prediction_index\u001b[1;34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[0m\n\u001b[0;32m    358\u001b[0m     start, _, start_oos \u001b[38;5;241m=\u001b[39m get_index_label_loc(\n\u001b[0;32m    359\u001b[0m         start, base_index, data\u001b[38;5;241m.\u001b[39mrow_labels\n\u001b[0;32m    360\u001b[0m     )\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `start` argument could not be matched to a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m location related to the index of the data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m     )\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(start, \u001b[38;5;28mlen\u001b[39m(base_index) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'The `start` argument could not be matched to a location related to the index of the data.'"
     ]
    }
   ],
   "source": [
    "# 예측할 기간 설정\n",
    "forecast_periods = 24\n",
    "\n",
    "# 예측에 사용할 새로운 인덱스 생성\n",
    "new_index = pd.date_range(start=df.index[-1], periods=forecast_periods+1, freq='H')[1:]\n",
    "\n",
    "# SARIMA 모델을 사용하여 예측\n",
    "forecast = result.predict(start=new_index[0], end=new_index[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_cuda",
   "language": "python",
   "name": "test_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
