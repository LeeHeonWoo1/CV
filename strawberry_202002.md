# 딥러닝을 활용한 딸기 생육 지표 인식

> https://www.kais99.org/jkais/journal/Vol24No11/vol24no11p063.pdf

## 소개
딸기 재배 중 필요한 농작업 의사결정에 활용될 Deep Learning기반 생육 지표 인식 모델을 제시한다. 다양한 생육 지표 인식은 수확로봇 뿐만 아니라 모니터링에 기반한 농작업 의사결정에 기여할 수 있다.

## 데이터 수집
- 2022년 7월부터 2023년 4월까지 설향 품종이 연동유리온실에서 고설 방식으로 재배되었고, 양상은 총 14회 취득됨
- 데이터의 다양성을 고려해 취득 시간은 9시에서 18시 사이에 촬영됨
- 촬영 각도와 대상과의 거리는 각각 범주에서 객체의 정보가 충분히 포함될 수 있는 위치 조건을 설정
- Frame60, Linear화각의 촬영 조건에서 동영상을 취득하고, 객체의 정보가 1개 이상 표현된 영상을 무작위하게 추출해 767장을 학습 데이터로 사용

## 데이터 처리
- Labelme로 polygon 생성(이 때, 영상 내에 재배 베드가 2개 이상 포함된 경우, 가장 가까운 베드에만 어노테이션)
- 인식 대상 지정
    + 재배 베드가 2개 이상이 포함된 경우, 가장 가까운 베드에 대해서만 실시
- 수집 클래스
    + 꽃 : 화아분화 후 꽃잎의 전개가 시작되기 직전부터 완전히 전개되어 꽃잎이 4개이상 확인되는 객체
    + 과실(성숙 전) : 꽃이 수정된 후 꽃잎이 떨어지기 시작하여 3개 이하가 된 이후부터 과실의 비대 전 과정
    + 과실(성숙기) : 착색이 완료되어 완전 성숙된 수확 대상의 과실
    + 수확지점 : 과실(성숙기) 객체를 대상으로 식별 가능한 꽃자루
    + Color checker : 영상 내 작물과 같이 촬영된 24개의 기준 색상을 포함한 color checker
    + 식별 불가 : 영상 내에서 생육 지표는 맞으나 class로 분류할 수 없는 객체. $90\degree$ 에 가까운 각도로 촬영된 영상에서 분류가 어려운 객체를 의미

학습데이터로 사용된 총 767장의 영상에서 각 클래스 별로 1,740, 4,478, 895, 652, 375, 1,143개의 객체가 annotation됨. 이를 train, val, test셋으로 분할하여 각 552, 138, 77장으로 분할되었으며 나뉜 class별 객체 수는 아래 표 참고

<div align=center><img src=./class_num_table.png></div>

## Model selection
해당 논문에서는 detection 계열 모델인 yolov3, 4, 5와 